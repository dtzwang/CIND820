{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4JCoOguwtKhF"
   },
   "outputs": [],
   "source": [
    "#Data processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Model performance metrics\n",
    "from time import process_time\n",
    "from memory_profiler import profile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Feature selection and models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Data scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Function\n",
    "def DTClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  tree_raw_imbalanced = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the Classifier to the data\n",
    "  tree_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = tree_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "def RFClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the Random Forest Classifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the classifier to the data\n",
    "  forest_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = forest_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "def LRClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the Logistic Regression Classifier\n",
    "  lr_raw_imbalanced = LogisticRegression(max_iter= 1000)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the classifier to the data\n",
    "  lr_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = lr_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "44OujbUttSSO"
   },
   "outputs": [],
   "source": [
    "#https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KRCsu3r5tZpJ"
   },
   "outputs": [],
   "source": [
    "#Identify categorical attributes\n",
    "categorical_features = [\"Month\", \"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\"]\n",
    "df_cat = df[categorical_features]\n",
    "\n",
    "df_onehot = pd.get_dummies(df, columns = categorical_features, prefix = categorical_features)\n",
    "\n",
    "#Tranform categorical attributes\n",
    "label_encoder = LabelEncoder()\n",
    "df_onehot['Revenue'] = label_encoder.fit_transform(df['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcUOdrF_tlUx"
   },
   "source": [
    "Control SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8rc2Vmy8texw"
   },
   "outputs": [],
   "source": [
    "#Specify independent/ dependent values\n",
    "X = df_onehot.drop(columns = \"Revenue\")\n",
    "y = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpMyEWmOtvjL"
   },
   "source": [
    "# Filtered Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHa8Kv3ptyvM"
   },
   "source": [
    "Pearson Correlation Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HrDrPu0tyFK",
    "outputId": "77ac05e8-4c20-49ec-d89b-e762c8772149"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_18248/4021719917.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pearson['Revenue'] = label_encoder.fit_transform(df_pearson['Revenue'])\n"
     ]
    }
   ],
   "source": [
    "#Correlation of Onehot encoded dataset\n",
    "\n",
    "corr = df_onehot.corr()\n",
    "\n",
    "revenue_correlation = corr[\"Revenue\"]\n",
    "sorted_pearson_correlation = revenue_correlation.abs().sort_values(ascending = False)\n",
    "\n",
    "#Filter out for attributes with correlation > 0.09\n",
    "filtered_correlation = sorted_pearson_correlation[sorted_pearson_correlation > 0.09]\n",
    "filtered_attributes = filtered_correlation.index.tolist()\n",
    "df_pearson = df_onehot[filtered_attributes]\n",
    "\n",
    "#12 attributes (Onehot encoded) are kept\n",
    "\n",
    "#Tranform categorical attributes\n",
    "label_encoder = LabelEncoder()\n",
    "df_pearson['Revenue'] = label_encoder.fit_transform(df_pearson['Revenue'])\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_p = df_pearson.drop(columns = \"Revenue\")\n",
    "y_p = df_pearson[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p, y_p, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_p_train_smote, y_p_train_smote = smote.fit_resample(X_p_train, y_p_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3Mm3aGPuXM0"
   },
   "source": [
    "Random Forest Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEM13opyuB5_",
    "outputId": "739e18dc-171b-43f9-b25a-f990e38acc59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_18248/4019081138.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rf[\"Revenue\"] = df_onehot[\"Revenue\"]\n"
     ]
    }
   ],
   "source": [
    "#Filters of RF Classifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "#Fit random forest classifier\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "rf_df = pd.DataFrame({\"Feature\": X_train_smote.columns, \"Importance\": feature_importances})\n",
    "\n",
    "sorted_features = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "#Sorting features\n",
    "rf_df_sorted = rf_df.sort_values(\"Importance\", ascending = False)\n",
    "rf_df_sorted = rf_df_sorted.reset_index(drop = True)\n",
    "rf_df_sorted\n",
    "\n",
    "#Filter out for attributes with random forest score > 0.009\n",
    "filtered_rf = rf_df_sorted[rf_df_sorted['Importance'] > 0.009]\n",
    "#filtered_attributes_rf = filtered_rf.index.tolist()\n",
    "df_rf = df_onehot[filtered_rf[\"Feature\"]]\n",
    "\n",
    "#24 features are kept after random forest feature selection\n",
    "df_rf[\"Revenue\"] = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_rf = df_rf.drop(columns = \"Revenue\")\n",
    "y_rf = df_rf[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_rf_train_smote, y_rf_train_smote = smote.fit_resample(X_rf_train, y_rf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq5mjUnIwAZm"
   },
   "source": [
    "RFE Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWe3lxDruOBD",
    "outputId": "95f8f52c-61c2-48aa-fe17-2114fd509dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indices: [6, 7, 9, 10, 12, 13, 17, 18, 19, 22, 30, 39, 50, 52, 56, 62, 64, 67, 73, 74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_18248/2182278487.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rfe[\"Revenue\"] = df_onehot[\"Revenue\"]\n"
     ]
    }
   ],
   "source": [
    "#Filter for features with RFE\n",
    "\n",
    "df_X_rfe = df_onehot.drop(columns = \"Revenue\")\n",
    "df_y_rfe = df_onehot[\"Revenue\"]\n",
    "\n",
    "# Instantiate the model and RFE selector\n",
    "model = LogisticRegression(solver = \"liblinear\")\n",
    "rfe_selector = RFE(model, n_features_to_select = 20)\n",
    "\n",
    "# Perform RFE feature selection\n",
    "selected_features = rfe_selector.fit_transform(df_X_rfe, df_y_rfe)\n",
    "\n",
    "# Get the mask of selected features\n",
    "feature_mask = rfe_selector.support_\n",
    "\n",
    "# Get the ranking of features (optional)\n",
    "feature_ranking = rfe_selector.ranking_\n",
    "\n",
    "selected_indices = [i for i, mask in enumerate(feature_mask) if mask]\n",
    "print(\"Selected feature indices:\", selected_indices)\n",
    "\n",
    "df_rfe = df_onehot.iloc[:, selected_indices]\n",
    "\n",
    "#20 features are kept after random forest feature selection\n",
    "df_rfe[\"Revenue\"] = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_rfe = df_rfe.drop(columns = \"Revenue\")\n",
    "y_rfe = df_rfe[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_rfe_train, X_rfe_test, y_rfe_train, y_rfe_test = train_test_split(X_rfe, y_rfe, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_rfe_train_smote, y_rfe_train_smote = smote.fit_resample(X_rfe_train, y_rfe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define columns that need data normalization/ standardization\n",
    "numeric_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "\n",
    "p_numeric_features = ['Administrative', 'Administrative_Duration', 'Informational', \n",
    "       'ProductRelated', 'ProductRelated_Duration','BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "rf_numeric_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "rfe_numeric_features = ['BounceRates', 'ExitRates', 'SpecialDay']\n",
    "\n",
    "cat_features = [col for col in X_train if col not in numeric_features]\n",
    "p_cat_features = [col for col in X_p_train if col not in numeric_features]\n",
    "rf_cat_features = [col for col in X_rf_train if col not in numeric_features]\n",
    "rfe_cat_features = [col for col in X_rfe_train if col not in numeric_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfiltered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      3124\n",
      "           1       0.55      0.59      0.57       575\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.75      0.74      3699\n",
      "weighted avg       0.86      0.86      0.86      3699\n",
      "\n",
      "[[2844  280]\n",
      " [ 238  337]]\n",
      "0.109375\n",
      "peak memory: 288.85 MiB, increment: 4.43 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_train_smote, y_train_smote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3124\n",
      "           1       0.68      0.62      0.65       575\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.78      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "[[2954  170]\n",
      " [ 220  355]]\n",
      "1.34375\n",
      "peak memory: 306.59 MiB, increment: 21.88 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_train_smote, y_train_smote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      3124\n",
      "           1       0.58      0.62      0.60       575\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.75      0.77      0.76      3699\n",
      "weighted avg       0.87      0.87      0.87      3699\n",
      "\n",
      "[[2862  262]\n",
      " [ 218  357]]\n",
      "0.09375\n",
      "peak memory: 294.27 MiB, increment: 9.27 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_train_smote, y_train_smote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91      3102\n",
      "           1       0.52      0.65      0.58       597\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.72      0.77      0.74      3699\n",
      "weighted avg       0.86      0.85      0.85      3699\n",
      "\n",
      "[[2737  365]\n",
      " [ 208  389]]\n",
      "0.09375\n",
      "peak memory: 286.80 MiB, increment: 0.88 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_p_train_smote, y_p_train_smote, X_p_test, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3102\n",
      "           1       0.60      0.74      0.66       597\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.77      0.82      0.79      3699\n",
      "weighted avg       0.89      0.88      0.88      3699\n",
      "\n",
      "[[2810  292]\n",
      " [ 157  440]]\n",
      "1.5\n",
      "peak memory: 301.36 MiB, increment: 17.08 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_p_train_smote, y_p_train_smote, X_p_test, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      3102\n",
      "           1       0.60      0.69      0.64       597\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.77      0.80      0.78      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n",
      "[[2832  270]\n",
      " [ 186  411]]\n",
      "0.046875\n",
      "peak memory: 287.21 MiB, increment: 1.91 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_p_train_smote, y_p_train_smote, X_p_test, y_p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      3129\n",
      "           1       0.54      0.61      0.57       570\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.76      0.75      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2830  299]\n",
      " [ 220  350]]\n",
      "0.09375\n",
      "peak memory: 286.21 MiB, increment: 0.35 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rf_train_smote, y_rf_train_smote, X_rf_test, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3129\n",
      "           1       0.65      0.68      0.67       570\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.81      0.80      3699\n",
      "weighted avg       0.90      0.89      0.90      3699\n",
      "\n",
      "[[2922  207]\n",
      " [ 182  388]]\n",
      "1.453125\n",
      "peak memory: 300.47 MiB, increment: 14.25 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rf_train_smote, y_rf_train_smote, X_rf_test, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3129\n",
      "           1       0.59      0.65      0.62       570\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.76      0.78      0.77      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n",
      "[[2866  263]\n",
      " [ 198  372]]\n",
      "0.0625\n",
      "peak memory: 287.60 MiB, increment: 4.20 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rf_train_smote, y_rf_train_smote, X_rf_test, y_rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80      3126\n",
      "           1       0.23      0.43      0.30       573\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.55      0.58      0.55      3699\n",
      "weighted avg       0.78      0.69      0.72      3699\n",
      "\n",
      "[[2299  827]\n",
      " [ 325  248]]\n",
      "0.046875\n",
      "peak memory: 285.92 MiB, increment: 1.21 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rfe_train_smote, y_rfe_train_smote, X_rfe_test, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83      3126\n",
      "           1       0.26      0.40      0.31       573\n",
      "\n",
      "    accuracy                           0.73      3699\n",
      "   macro avg       0.57      0.59      0.57      3699\n",
      "weighted avg       0.78      0.73      0.75      3699\n",
      "\n",
      "[[2452  674]\n",
      " [ 342  231]]\n",
      "1.046875\n",
      "peak memory: 326.17 MiB, increment: 42.30 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rfe_train_smote, y_rfe_train_smote, X_rfe_test, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75      3126\n",
      "           1       0.26      0.70      0.38       573\n",
      "\n",
      "    accuracy                           0.64      3699\n",
      "   macro avg       0.59      0.67      0.56      3699\n",
      "weighted avg       0.82      0.64      0.69      3699\n",
      "\n",
      "[[1980 1146]\n",
      " [ 173  400]]\n",
      "0.046875\n",
      "peak memory: 285.88 MiB, increment: 2.70 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rfe_train_smote, y_rfe_train_smote, X_rfe_test, y_rfe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting data to scale numeric features\n",
    "\n",
    "#Control\n",
    "X_train_smote_NUM = X_train_smote[numeric_features]\n",
    "X_test_NUM = X_test[numeric_features]\n",
    "\n",
    "#Pearson correlation features\n",
    "X_p_train_smote_NUM = X_p_train_smote[p_numeric_features]\n",
    "X_p_test_NUM = X_p_test[p_numeric_features]\n",
    "\n",
    "#Random Forest features\n",
    "X_rf_train_smote_NUM = X_rf_train_smote[rf_numeric_features]\n",
    "X_rf_test_NUM = X_rf_test[rf_numeric_features]\n",
    "\n",
    "#Recursive Feature Elimination features\n",
    "X_rfe_train_smote_NUM = X_rfe_train_smote[rfe_numeric_features]\n",
    "X_rfe_test_NUM = X_rfe_test[rfe_numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5FIhEwvgwyOR"
   },
   "outputs": [],
   "source": [
    "nscaler = MinMaxScaler()\n",
    "\n",
    "#Scaling control\n",
    "X_train_smote_NUM_N = nscaler.fit_transform(X_train_smote_NUM)\n",
    "X_train_smote_COMBINED_N = np.concatenate((X_train_smote_NUM_N, X_train_smote[cat_features]), axis = 1)\n",
    "                                          \n",
    "X_test_NUM_N = nscaler.transform(X_test_NUM)\n",
    "X_test_COMBINED_N = np.concatenate((X_test_NUM_N, X_test[cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Pearson correlation features\n",
    "X_p_train_smote_NUM_N = nscaler.fit_transform(X_p_train_smote_NUM)\n",
    "X_p_train_smote_COMBINED_N = np.concatenate((X_p_train_smote_NUM_N, X_p_train_smote[p_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_p_test_NUM_N = nscaler.transform(X_p_test_NUM)\n",
    "X_p_test_COMBINED_N = np.concatenate((X_p_test_NUM_N, X_p_test[p_cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Random Forest features\n",
    "X_rf_train_smote_NUM_N = nscaler.fit_transform(X_rf_train_smote_NUM)\n",
    "X_rf_train_smote_COMBINED_N = np.concatenate((X_rf_train_smote_NUM_N, X_rf_train_smote[rf_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_rf_test_NUM_N = nscaler.transform(X_rf_test_NUM)\n",
    "X_rf_test_COMBINED_N = np.concatenate((X_rf_test_NUM_N, X_rf_test[rf_cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Recursive Feature Elimination features\n",
    "X_rfe_train_smote_NUM_N = nscaler.fit_transform(X_rfe_train_smote_NUM)\n",
    "X_rfe_train_smote_COMBINED_N = np.concatenate((X_rfe_train_smote_NUM_N, X_rfe_train_smote[rfe_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_rfe_test_NUM_N = nscaler.transform(X_rfe_test_NUM)\n",
    "X_rfe_test_COMBINED_N = np.concatenate((X_rfe_test_NUM_N, X_rfe_test[rfe_cat_features]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Models on Normalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control features - Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      3124\n",
      "           1       0.55      0.59      0.57       575\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.74      0.75      0.74      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2848  276]\n",
      " [ 235  340]]\n",
      "0.109375\n",
      "peak memory: 285.46 MiB, increment: 0.09 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_train_smote_COMBINED_N, y_train_smote, X_test_COMBINED_N, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3124\n",
      "           1       0.67      0.61      0.64       575\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.78      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "[[2954  170]\n",
      " [ 223  352]]\n",
      "1.28125\n",
      "peak memory: 307.96 MiB, increment: 22.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_train_smote_COMBINED_N, y_train_smote, X_test_COMBINED_N, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      3124\n",
      "           1       0.71      0.27      0.39       575\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.80      0.63      0.66      3699\n",
      "weighted avg       0.85      0.87      0.84      3699\n",
      "\n",
      "[[3060   64]\n",
      " [ 418  157]]\n",
      "0.09375\n",
      "peak memory: 320.32 MiB, increment: 8.36 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_train_smote_COMBINED_N, y_train_smote, X_test_COMBINED_N, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation features - normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      3102\n",
      "           1       0.51      0.64      0.57       597\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.72      0.76      0.74      3699\n",
      "weighted avg       0.86      0.84      0.85      3699\n",
      "\n",
      "[[2739  363]\n",
      " [ 215  382]]\n",
      "0.078125\n",
      "peak memory: 284.83 MiB, increment: 1.07 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_p_train_smote_COMBINED_N, y_p_train_smote, X_p_test_COMBINED_N, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3102\n",
      "           1       0.60      0.75      0.67       597\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.83      0.80      3699\n",
      "weighted avg       0.89      0.88      0.88      3699\n",
      "\n",
      "[[2809  293]\n",
      " [ 152  445]]\n",
      "1.5\n",
      "peak memory: 301.49 MiB, increment: 16.65 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_p_train_smote_COMBINED_N, y_p_train_smote, X_p_test_COMBINED_N, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      3102\n",
      "           1       0.55      0.64      0.59       597\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.74      0.77      0.75      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2786  316]\n",
      " [ 216  381]]\n",
      "0.046875\n",
      "peak memory: 286.19 MiB, increment: 1.36 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_p_train_smote_COMBINED_N, y_p_train_smote, X_p_test_COMBINED_N, y_p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest features - normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      3129\n",
      "           1       0.53      0.60      0.56       570\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.75      0.74      3699\n",
      "weighted avg       0.86      0.86      0.86      3699\n",
      "\n",
      "[[2831  298]\n",
      " [ 230  340]]\n",
      "0.09375\n",
      "peak memory: 285.58 MiB, increment: 0.88 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rf_train_smote_COMBINED_N, y_rf_train_smote, X_rf_test_COMBINED_N, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3129\n",
      "           1       0.65      0.67      0.66       570\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.80      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2924  205]\n",
      " [ 188  382]]\n",
      "1.484375\n",
      "peak memory: 299.86 MiB, increment: 14.28 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rf_train_smote_COMBINED_N, y_rf_train_smote, X_rf_test_COMBINED_N, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      3129\n",
      "           1       0.54      0.44      0.48       570\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.72      0.69      0.70      3699\n",
      "weighted avg       0.85      0.86      0.85      3699\n",
      "\n",
      "[[2921  208]\n",
      " [ 321  249]]\n",
      "0.0625\n",
      "peak memory: 314.86 MiB, increment: 2.89 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rf_train_smote_COMBINED_N, y_rf_train_smote, X_rf_test_COMBINED_N, y_rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination - normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80      3126\n",
      "           1       0.23      0.44      0.31       573\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.56      0.59      0.55      3699\n",
      "weighted avg       0.78      0.69      0.72      3699\n",
      "\n",
      "[[2302  824]\n",
      " [ 321  252]]\n",
      "0.046875\n",
      "peak memory: 285.40 MiB, increment: 0.59 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rfe_train_smote_COMBINED_N, y_rfe_train_smote, X_rfe_test_COMBINED_N, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83      3126\n",
      "           1       0.25      0.40      0.31       573\n",
      "\n",
      "    accuracy                           0.72      3699\n",
      "   macro avg       0.57      0.59      0.57      3699\n",
      "weighted avg       0.78      0.72      0.75      3699\n",
      "\n",
      "[[2447  679]\n",
      " [ 343  230]]\n",
      "1.0625\n",
      "peak memory: 326.44 MiB, increment: 40.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rfe_train_smote_COMBINED_N, y_rfe_train_smote, X_rfe_test_COMBINED_N, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74      3126\n",
      "           1       0.25      0.70      0.37       573\n",
      "\n",
      "    accuracy                           0.63      3699\n",
      "   macro avg       0.59      0.66      0.56      3699\n",
      "weighted avg       0.82      0.63      0.68      3699\n",
      "\n",
      "[[1940 1186]\n",
      " [ 170  403]]\n",
      "0.046875\n",
      "peak memory: 314.08 MiB, increment: 2.12 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rfe_train_smote_COMBINED_N, y_rfe_train_smote, X_rfe_test_COMBINED_N, y_rfe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscaler = StandardScaler()\n",
    "\n",
    "#Scaling control\n",
    "X_train_smote_NUM_S = sscaler.fit_transform(X_train_smote_NUM)\n",
    "X_train_smote_COMBINED_S = np.concatenate((X_train_smote_NUM_S, X_train_smote[cat_features]), axis = 1)\n",
    "                                          \n",
    "X_test_NUM_S = sscaler.transform(X_test_NUM)\n",
    "X_test_COMBINED_S = np.concatenate((X_test_NUM_S, X_test[cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Pearson correlation features\n",
    "X_p_train_smote_NUM_S = sscaler.fit_transform(X_p_train_smote_NUM)\n",
    "X_p_train_smote_COMBINED_S = np.concatenate((X_p_train_smote_NUM_S, X_p_train_smote[p_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_p_test_NUM_S = sscaler.transform(X_p_test_NUM)\n",
    "X_p_test_COMBINED_S = np.concatenate((X_p_test_NUM_S, X_p_test[p_cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Random Forest features\n",
    "X_rf_train_smote_NUM_S = sscaler.fit_transform(X_rf_train_smote_NUM)\n",
    "X_rf_train_smote_COMBINED_S = np.concatenate((X_rf_train_smote_NUM_S, X_rf_train_smote[rf_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_rf_test_NUM_S = sscaler.transform(X_rf_test_NUM)\n",
    "X_rf_test_COMBINED_S = np.concatenate((X_rf_test_NUM_S, X_rf_test[rf_cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Recursive Feature Elimination features\n",
    "X_rfe_train_smote_NUM_S = sscaler.fit_transform(X_rfe_train_smote_NUM)\n",
    "X_rfe_train_smote_COMBINED_S = np.concatenate((X_rfe_train_smote_NUM_S, X_rfe_train_smote[rfe_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_rfe_test_NUM_S = sscaler.transform(X_rfe_test_NUM)\n",
    "X_rfe_test_COMBINED_S = np.concatenate((X_rfe_test_NUM_S, X_rfe_test[rfe_cat_features]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control data - Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      3124\n",
      "           1       0.54      0.60      0.57       575\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.75      0.74      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2835  289]\n",
      " [ 232  343]]\n",
      "0.109375\n",
      "peak memory: 308.53 MiB, increment: 0.61 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_train_smote_COMBINED_S, y_train_smote, X_test_COMBINED_S, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3124\n",
      "           1       0.68      0.62      0.65       575\n",
      "\n",
      "    accuracy                           0.90      3699\n",
      "   macro avg       0.81      0.78      0.79      3699\n",
      "weighted avg       0.89      0.90      0.89      3699\n",
      "\n",
      "[[2960  164]\n",
      " [ 219  356]]\n",
      "1.296875\n",
      "peak memory: 328.95 MiB, increment: 20.42 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_train_smote_COMBINED_S, y_train_smote, X_test_COMBINED_S, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      3124\n",
      "           1       0.69      0.38      0.49       575\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.79      0.67      0.71      3699\n",
      "weighted avg       0.86      0.88      0.86      3699\n",
      "\n",
      "[[3029   95]\n",
      " [ 359  216]]\n",
      "0.125\n",
      "peak memory: 320.32 MiB, increment: 8.38 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_train_smote_COMBINED_S, y_train_smote, X_test_COMBINED_S, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      3102\n",
      "           1       0.51      0.65      0.57       597\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.72      0.76      0.74      3699\n",
      "weighted avg       0.86      0.84      0.85      3699\n",
      "\n",
      "[[2733  369]\n",
      " [ 210  387]]\n",
      "0.078125\n",
      "peak memory: 312.39 MiB, increment: 0.43 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_p_train_smote_COMBINED_S, y_p_train_smote, X_p_test_COMBINED_S, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93      3102\n",
      "           1       0.60      0.74      0.66       597\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.77      0.82      0.79      3699\n",
      "weighted avg       0.89      0.88      0.88      3699\n",
      "\n",
      "[[2805  297]\n",
      " [ 155  442]]\n",
      "1.515625\n",
      "peak memory: 325.98 MiB, increment: 13.58 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_p_train_smote_COMBINED_S, y_p_train_smote, X_p_test_COMBINED_S, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      3102\n",
      "           1       0.58      0.70      0.64       597\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.76      0.80      0.78      3699\n",
      "weighted avg       0.88      0.87      0.88      3699\n",
      "\n",
      "[[2807  295]\n",
      " [ 182  415]]\n",
      "0.015625\n",
      "peak memory: 311.66 MiB, increment: 1.96 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_p_train_smote_COMBINED_S, y_p_train_smote, X_p_test_COMBINED_S, y_p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest features - standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      3129\n",
      "           1       0.54      0.59      0.57       570\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.75      0.74      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2844  285]\n",
      " [ 231  339]]\n",
      "0.078125\n",
      "peak memory: 311.00 MiB, increment: 0.68 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rf_train_smote_COMBINED_S, y_rf_train_smote, X_rf_test_COMBINED_S, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3129\n",
      "           1       0.65      0.68      0.66       570\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.80      0.80      3699\n",
      "weighted avg       0.90      0.89      0.90      3699\n",
      "\n",
      "[[2924  205]\n",
      " [ 185  385]]\n",
      "1.421875\n",
      "peak memory: 325.11 MiB, increment: 14.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rf_train_smote_COMBINED_S, y_rf_train_smote, X_rf_test_COMBINED_S, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      3129\n",
      "           1       0.60      0.52      0.55       570\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.76      0.73      0.74      3699\n",
      "weighted avg       0.87      0.87      0.87      3699\n",
      "\n",
      "[[2932  197]\n",
      " [ 276  294]]\n",
      "0.046875\n",
      "peak memory: 311.34 MiB, increment: 3.64 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rf_train_smote_COMBINED_S, y_rf_train_smote, X_rf_test_COMBINED_S, y_rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination features - standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      3126\n",
      "           1       0.23      0.43      0.30       573\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.55      0.58      0.55      3699\n",
      "weighted avg       0.78      0.69      0.72      3699\n",
      "\n",
      "[[2291  835]\n",
      " [ 325  248]]\n",
      "0.046875\n",
      "peak memory: 308.95 MiB, increment: 0.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rfe_train_smote_COMBINED_S, y_rfe_train_smote, X_rfe_test_COMBINED_S, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83      3126\n",
      "           1       0.25      0.40      0.31       573\n",
      "\n",
      "    accuracy                           0.72      3699\n",
      "   macro avg       0.57      0.59      0.57      3699\n",
      "weighted avg       0.78      0.72      0.75      3699\n",
      "\n",
      "[[2445  681]\n",
      " [ 342  231]]\n",
      "1.296875\n",
      "peak memory: 350.70 MiB, increment: 41.75 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rfe_train_smote_COMBINED_S, y_rfe_train_smote, X_rfe_test_COMBINED_S, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74      3126\n",
      "           1       0.25      0.70      0.37       573\n",
      "\n",
      "    accuracy                           0.63      3699\n",
      "   macro avg       0.59      0.66      0.56      3699\n",
      "weighted avg       0.81      0.63      0.68      3699\n",
      "\n",
      "[[1945 1181]\n",
      " [ 174  399]]\n",
      "0.03125\n",
      "peak memory: 312.72 MiB, increment: 2.69 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rfe_train_smote_COMBINED_S, y_rfe_train_smote, X_rfe_test_COMBINED_S, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
