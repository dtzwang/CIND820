{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4JCoOguwtKhF"
   },
   "outputs": [],
   "source": [
    "#Data processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Model performance metrics\n",
    "from time import process_time\n",
    "from memory_profiler import profile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Feature selection and models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Data scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Metrics\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "def RFClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the Random Forest Classifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the classifier to the data\n",
    "  forest_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = forest_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Models to include SMOTE and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest function\n",
    "def RFClassifierMOD(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_estimators):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = num_estimators)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "  \n",
    "  #Data preprocessing\n",
    "  smote = SMOTE()\n",
    "  X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "  # Subset the numeric attributes\n",
    "  X_train_smote_numeric = X_train_smote[numeric_attributes]\n",
    "  X_test_numeric = X_test[numeric_attributes]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X_train_smote_S = scaler.fit_transform(X_train_smote_numeric)\n",
    "  X_test_numeric_S = scaler.transform(X_test_numeric)\n",
    "        \n",
    "  # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "  X_train_combined = np.concatenate((X_train_smote_S, X_train_smote[cat_attributes]), axis=1)\n",
    "  X_test_combined = np.concatenate((X_test_numeric_S, X_test[cat_attributes]), axis=1)\n",
    "\n",
    "  #Fit the Classifier to the data\n",
    "  forest_raw_imbalanced.fit(X_train_combined, y_train_smote)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = forest_raw_imbalanced.predict(X_test_combined)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  mcc = matthews_corrcoef(y_test, y_pred)\n",
    "  brier_score = brier_score_loss(y_test, y_pred)\n",
    "  print(\"Matthew's Correlation\", mcc)\n",
    "  print(\"Brier's Score\", brier_score)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossvalidation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Validation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Function\n",
    "def RFClassifierKFold(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_estimators, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = num_estimators)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  kfold = KFold(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(forest_raw_imbalanced, X_train, y_train, cv = kfold)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "  mcc_scores = []\n",
    "  brier_scores = []\n",
    "    \n",
    "  for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    forest_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = forest_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "    \n",
    "    mcc_scores.append(matthews_corrcoef(y_val_fold, y_pred))\n",
    "    brier_scores.append(brier_score_loss(y_val_fold, y_pred))\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "  \n",
    "  print(summary_report)\n",
    "  \n",
    "  print(\"Matthew's Correlation\", sum(mcc_scores) / len(mcc_scores))\n",
    "  print(\"Brier's Score\", sum(brier_scores) / len(brier_scores))\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Function\n",
    "def RFClassifierTS(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_estimators, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = num_estimators)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  tscv = TimeSeriesSplit(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(forest_raw_imbalanced, X_train, y_train, cv = tscv)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "  mcc_scores = []\n",
    "  brier_scores = []\n",
    "    \n",
    "  for train_index, val_index in tscv.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    forest_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = forest_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "    \n",
    "    mcc_scores.append(matthews_corrcoef(y_val_fold, y_pred))\n",
    "    brier_scores.append(brier_score_loss(y_val_fold, y_pred))\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(\"Matthew's Correlation\", sum(mcc_scores) / len(mcc_scores))\n",
    "  print(\"Brier's Score\", sum(brier_scores) / len(brier_scores))\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "44OujbUttSSO"
   },
   "outputs": [],
   "source": [
    "#https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KRCsu3r5tZpJ"
   },
   "outputs": [],
   "source": [
    "#Identify categorical attributes\n",
    "categorical_features = [\"Month\", \"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\"]\n",
    "df_cat = df[categorical_features]\n",
    "\n",
    "df_onehot = pd.get_dummies(df, columns = categorical_features, prefix = categorical_features)\n",
    "\n",
    "#Tranform categorical attributes\n",
    "label_encoder = LabelEncoder()\n",
    "df_onehot['Revenue'] = label_encoder.fit_transform(df['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcUOdrF_tlUx"
   },
   "source": [
    "Control SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8rc2Vmy8texw"
   },
   "outputs": [],
   "source": [
    "#Specify independent/ dependent values\n",
    "X = df_onehot.drop(columns = \"Revenue\")\n",
    "y = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpMyEWmOtvjL"
   },
   "source": [
    "# Filtered Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHa8Kv3ptyvM"
   },
   "source": [
    "Pearson Correlation Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HrDrPu0tyFK",
    "outputId": "77ac05e8-4c20-49ec-d89b-e762c8772149"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_22312/402327404.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pearson['Revenue'] = label_encoder.fit_transform(df_pearson['Revenue'])\n"
     ]
    }
   ],
   "source": [
    "#Correlation of Onehot encoded dataset\n",
    "\n",
    "corr = df_onehot.corr()\n",
    "\n",
    "revenue_correlation = corr[\"Revenue\"]\n",
    "sorted_pearson_correlation = revenue_correlation.abs().sort_values(ascending = False)\n",
    "\n",
    "sorted_pearson_correlation_df = pd.DataFrame(sorted_pearson_correlation)\n",
    "SPC_topquantile = sorted_pearson_correlation_df.quantile(0.75)\n",
    "filtered_df = sorted_pearson_correlation_df[sorted_pearson_correlation_df >= SPC_topquantile]\n",
    "filtered_df.dropna(inplace = True)\n",
    "#18 attributes were kept, were in the top quantile\n",
    "     \n",
    "df_pearson = df_onehot[filtered_df.index.tolist()]\n",
    "\n",
    "#Tranform categorical attributes\n",
    "label_encoder = LabelEncoder()\n",
    "df_pearson['Revenue'] = label_encoder.fit_transform(df_pearson['Revenue'])\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_p = df_pearson.drop(columns = \"Revenue\")\n",
    "y_p = df_pearson[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p, y_p, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_p_train_smote, y_p_train_smote = smote.fit_resample(X_p_train, y_p_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3Mm3aGPuXM0"
   },
   "source": [
    "Random Forest Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEM13opyuB5_",
    "outputId": "739e18dc-171b-43f9-b25a-f990e38acc59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_22312/1307179630.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rf[\"Revenue\"] = df_onehot[\"Revenue\"]\n"
     ]
    }
   ],
   "source": [
    "#Filters of RF Classifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "#Fit random forest classifier\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "rf_df = pd.DataFrame({\"Feature\": X_train_smote.columns, \"Importance\": feature_importances})\n",
    "\n",
    "sorted_features = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "#Sorting features\n",
    "rf_df_sorted = rf_df.sort_values(\"Importance\", ascending = False)\n",
    "rf_df_sorted = rf_df_sorted.reset_index(drop = True)\n",
    "rf_df_sorted\n",
    "\n",
    "rf_df_sorted.describe()\n",
    "RF_topquantile = rf_df_sorted['Importance'].quantile(0.75)\n",
    "RFfiltered_df = rf_df_sorted.loc[rf_df_sorted['Importance'] >= RF_topquantile]\n",
    "#19 features were kept after keeping the top quartile of results\n",
    "filtered_attributes_rf = RFfiltered_df.index.tolist()\n",
    "df_rf = df_onehot[RFfiltered_df[\"Feature\"]]\n",
    "\n",
    "df_rf[\"Revenue\"] = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_rf = df_rf.drop(columns = \"Revenue\")\n",
    "y_rf = df_rf[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_rf_train_smote, y_rf_train_smote = smote.fit_resample(X_rf_train, y_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define columns that need data normalization/ standardization\n",
    "numeric_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "\n",
    "p_numeric_features = ['Administrative', 'Administrative_Duration', 'Informational', \n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration','BounceRates',\n",
    "       'ExitRates', 'PageValues', 'SpecialDay']\n",
    "\n",
    "rf_numeric_features = ['Administrative', 'Administrative_Duration',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "cat_features = [col for col in X_train if col not in numeric_features]\n",
    "p_cat_features = [col for col in X_p_train if col not in numeric_features]\n",
    "rf_cat_features = [col for col in X_rf_train if col not in numeric_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing num_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Functions to include oversampling/scaling within the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      3142\n",
      "           1       0.62      0.72      0.67       557\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.82      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2896  246]\n",
      " [ 155  402]]\n",
      "Matthew's Correlation 0.6053729457758509\n",
      "Brier's Score 0.10840767775074345\n",
      "2.515625\n",
      "peak memory: 235.11 MiB, increment: 26.63 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierMOD(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Crossvalidation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      7322\n",
      "           1       0.73      0.56      0.63      1309\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.90      0.90      0.90      8631\n",
      "\n",
      "Matthew's Correlation 0.5861738150298498\n",
      "Brier's Score 0.09778750819410346\n",
      "9.6875\n",
      "peak memory: 244.31 MiB, increment: 13.37 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierKFold(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      6097\n",
      "           1       0.73      0.56      0.64      1093\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.83      0.76      0.79      7190\n",
      "weighted avg       0.90      0.90      0.90      7190\n",
      "\n",
      "Matthew's Correlation 0.5876567535109676\n",
      "Brier's Score 0.09791376912378304\n",
      "6.40625\n",
      "peak memory: 236.40 MiB, increment: 16.63 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierTS(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      3142\n",
      "           1       0.62      0.72      0.67       557\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.82      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2897  245]\n",
      " [ 157  400]]\n",
      "Matthew's Correlation 0.6033965770959435\n",
      "Brier's Score 0.10867802108678021\n",
      "2.4375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      3142\n",
      "           1       0.62      0.72      0.67       557\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.82      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2899  243]\n",
      " [ 157  400]]\n",
      "Matthew's Correlation 0.6047371915042924\n",
      "Brier's Score 0.10813733441470667\n",
      "2.5625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      3142\n",
      "           1       0.62      0.72      0.67       557\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.82      0.80      3699\n",
      "weighted avg       0.90      0.89      0.90      3699\n",
      "\n",
      "[[2898  244]\n",
      " [ 156  401]]\n",
      "Matthew's Correlation 0.605388806151251\n",
      "Brier's Score 0.10813733441470667\n",
      "2.640625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      3142\n",
      "           1       0.63      0.71      0.67       557\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.82      0.80      3699\n",
      "weighted avg       0.90      0.89      0.90      3699\n",
      "\n",
      "[[2904  238]\n",
      " [ 160  397]]\n",
      "Matthew's Correlation 0.6041407710751439\n",
      "Brier's Score 0.10759664774263314\n",
      "2.40625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      3142\n",
      "           1       0.62      0.71      0.66       557\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.82      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2895  247]\n",
      " [ 159  398]]\n",
      "Matthew's Correlation 0.5994121189853286\n",
      "Brier's Score 0.10975939443092728\n",
      "2.421875\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    RFClassifierMOD(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Precision Variance: 0.0\n",
      "Negative Recall Variance: 1.232595164407831e-32\n",
      "Negative F1-score Variance: 1.5999999999999674e-05\n",
      "Positive Precision Variance: 1.600000000000003e-05\n",
      "Positive Recall Variance: 2.400000000000004e-05\n",
      "Positive F1-score Variance: 1.600000000000003e-05\n",
      "Accuracy Variance: 0.0\n",
      "Matthew's Correlation Variance: 4.4388481056110005e-06\n",
      "Brier's Score Variance: 5.379094223386346e-07\n",
      "Time Variance: 0.00845703125\n"
     ]
    }
   ],
   "source": [
    "negative_precision = [0.95, 0.95, 0.95, 0.95, 0.95]\n",
    "negative_recall = [0.92, 0.92, 0.92, 0.92, 0.92]\n",
    "negative_f1_score = [0.94, 0.94, 0.94, 0.94, 0.93]\n",
    "\n",
    "positive_precision = [0.62, 0.62, 0.62, 0.63, 0.62]\n",
    "positive_recall = [0.72, 0.72, 0.72, 0.71, 0.71]\n",
    "positive_f1_score = [0.67, 0.67, 0.67, 0.67, 0.66]\n",
    "\n",
    "accuracy = [0.89, 0.89, 0.89, 0.89, 0.89]\n",
    "matthews_correlation = [0.6033965770959435, 0.6047371915042924, 0.605388806151251, 0.6041407710751439, 0.5994121189853286]\n",
    "briers_score = [0.10867802108678021, 0.10813733441470667, 0.10813733441470667, 0.10759664774263314, 0.10975939443092728]\n",
    "time = [2.4375, 2.5625, 2.640625, 2.40625, 2.421875]\n",
    "\n",
    "negative_precision_variance = np.var(negative_precision)\n",
    "negative_recall_variance = np.var(negative_recall)\n",
    "negative_f1_score_variance = np.var(negative_f1_score)\n",
    "\n",
    "positive_precision_variance = np.var(positive_precision)\n",
    "positive_recall_variance = np.var(positive_recall)\n",
    "positive_f1_score_variance = np.var(positive_f1_score)\n",
    "\n",
    "accuracy_variance = np.var(accuracy)\n",
    "matthews_correlation_variance = np.var(matthews_correlation)\n",
    "briers_score_variance = np.var(briers_score)\n",
    "time_variance = np.var(time)\n",
    "\n",
    "# Print the variances\n",
    "print(\"Negative Precision Variance:\", negative_precision_variance)\n",
    "print(\"Negative Recall Variance:\", negative_recall_variance)\n",
    "print(\"Negative F1-score Variance:\", negative_f1_score_variance)\n",
    "\n",
    "print(\"Positive Precision Variance:\", positive_precision_variance)\n",
    "print(\"Positive Recall Variance:\", positive_recall_variance)\n",
    "print(\"Positive F1-score Variance:\", positive_f1_score_variance)\n",
    "\n",
    "print(\"Accuracy Variance:\", accuracy_variance)\n",
    "print(\"Matthew's Correlation Variance:\", matthews_correlation_variance)\n",
    "print(\"Brier's Score Variance:\", briers_score_variance)\n",
    "print(\"Time Variance:\", time_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7322\n",
      "           1       0.74      0.56      0.64      1309\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.90      0.90      0.90      8631\n",
      "\n",
      "Matthew's Correlation 0.592160875692654\n",
      "Brier's Score 0.09616526022191343\n",
      "9.828125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7322\n",
      "           1       0.74      0.56      0.64      1309\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.90      0.90      0.90      8631\n",
      "\n",
      "Matthew's Correlation 0.5909500464579447\n",
      "Brier's Score 0.09639761379655543\n",
      "9.671875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7322\n",
      "           1       0.74      0.54      0.63      1309\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.75      0.78      8631\n",
      "weighted avg       0.89      0.90      0.90      8631\n",
      "\n",
      "Matthew's Correlation 0.5801427937530301\n",
      "Brier's Score 0.09836674827781247\n",
      "9.765625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7322\n",
      "           1       0.74      0.55      0.63      1309\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.90      0.90      0.90      8631\n",
      "\n",
      "Matthew's Correlation 0.5838126426649801\n",
      "Brier's Score 0.0976717004349836\n",
      "9.65625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      7322\n",
      "           1       0.74      0.56      0.64      1309\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.90      0.90      0.90      8631\n",
      "\n",
      "Matthew's Correlation 0.5921939573121014\n",
      "Brier's Score 0.0963970099322263\n",
      "9.515625\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    RFClassifierKFold(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Precision Variance: 1.232595164407831e-32\n",
      "Negative Recall Variance: 2.400000000000004e-05\n",
      "Negative F1-score Variance: 1.232595164407831e-32\n",
      "Positive Precision Variance: 0.0\n",
      "Positive Recall Variance: 2.400000000000004e-05\n",
      "Positive F1-score Variance: 2.400000000000004e-05\n",
      "Accuracy Variance: 0.0\n",
      "Matthew's Correlation Variance: 7.621492401814735e-06\n",
      "Brier's Score Variance: 2.7592693214958056e-07\n",
      "Time Variance: 0.04556640625\n"
     ]
    }
   ],
   "source": [
    "negative_precision = [0.92, 0.92, 0.92, 0.92, 0.92]\n",
    "negative_recall = [0.97, 0.97, 0.97, 0.96, 0.96]\n",
    "negative_f1_score = [0.94, 0.94, 0.94, 0.94, 0.94]\n",
    "\n",
    "positive_precision = [0.74, 0.74, 0.74, 0.74, 0.74]\n",
    "positive_recall = [0.56, 0.55, 0.55, 0.55, 0.56]\n",
    "positive_f1_score = [0.64, 0.63, 0.63, 0.63, 0.64]\n",
    "\n",
    "accuracy = [0.90, 0.90, 0.90, 0.90, 0.90]\n",
    "matthews_correlation = [0.5897665120780788, 0.5833569514943414, 0.584062157761428, 0.5860958315439827, 0.589897709880703]\n",
    "briers_score = [0.09674443320958588, 0.09801878823216033, 0.09778744109806689, 0.09743961524448788, 0.09674476868976872]\n",
    "time = [9.453125, 9.578125, 9.546875, 9.96875, 9.9375]\n",
    "\n",
    "negative_precision_variance = np.var(negative_precision)\n",
    "negative_recall_variance = np.var(negative_recall)\n",
    "negative_f1_score_variance = np.var(negative_f1_score)\n",
    "\n",
    "positive_precision_variance = np.var(positive_precision)\n",
    "positive_recall_variance = np.var(positive_recall)\n",
    "positive_f1_score_variance = np.var(positive_f1_score)\n",
    "\n",
    "accuracy_variance = np.var(accuracy)\n",
    "matthews_correlation_variance = np.var(matthews_correlation)\n",
    "briers_score_variance = np.var(briers_score)\n",
    "time_variance = np.var(time)\n",
    "\n",
    "# Print the variances\n",
    "print(\"Negative Precision Variance:\", negative_precision_variance)\n",
    "print(\"Negative Recall Variance:\", negative_recall_variance)\n",
    "print(\"Negative F1-score Variance:\", negative_f1_score_variance)\n",
    "\n",
    "print(\"Positive Precision Variance:\", positive_precision_variance)\n",
    "print(\"Positive Recall Variance:\", positive_recall_variance)\n",
    "print(\"Positive F1-score Variance:\", positive_f1_score_variance)\n",
    "\n",
    "print(\"Accuracy Variance:\", accuracy_variance)\n",
    "print(\"Matthew's Correlation Variance:\", matthews_correlation_variance)\n",
    "print(\"Brier's Score Variance:\", briers_score_variance)\n",
    "print(\"Time Variance:\", time_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      6097\n",
      "           1       0.74      0.56      0.64      1093\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.83      0.76      0.79      7190\n",
      "weighted avg       0.90      0.90      0.90      7190\n",
      "\n",
      "Matthew's Correlation 0.5897683347185898\n",
      "Brier's Score 0.0968011126564673\n",
      "6.71875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      6097\n",
      "           1       0.74      0.56      0.64      1093\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.83      0.76      0.79      7190\n",
      "weighted avg       0.90      0.90      0.90      7190\n",
      "\n",
      "Matthew's Correlation 0.5912042015863317\n",
      "Brier's Score 0.09638386648122392\n",
      "6.546875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      6097\n",
      "           1       0.73      0.57      0.64      1093\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.83      0.76      0.79      7190\n",
      "weighted avg       0.90      0.90      0.90      7190\n",
      "\n",
      "Matthew's Correlation 0.5893192697464371\n",
      "Brier's Score 0.09735744089012517\n",
      "6.390625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      6097\n",
      "           1       0.74      0.55      0.63      1093\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.83      0.76      0.79      7190\n",
      "weighted avg       0.90      0.90      0.90      7190\n",
      "\n",
      "Matthew's Correlation 0.5847338869126286\n",
      "Brier's Score 0.09791376912378304\n",
      "6.53125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      6097\n",
      "           1       0.73      0.55      0.63      1093\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.83      0.76      0.79      7190\n",
      "weighted avg       0.89      0.90      0.89      7190\n",
      "\n",
      "Matthew's Correlation 0.5794291285215211\n",
      "Brier's Score 0.09916550764951321\n",
      "6.515625\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    RFClassifierTS(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Precision Variance: 1.600000000000003e-05\n",
      "Negative Recall Variance: 2.4000000000000045e-05\n",
      "Negative F1-score Variance: 1.232595164407831e-32\n",
      "Positive Precision Variance: 2.400000000000004e-05\n",
      "Positive Recall Variance: 2.4000000000000048e-05\n",
      "Positive F1-score Variance: 2.4000000000000048e-05\n",
      "Accuracy Variance: 0.0\n",
      "Matthew's Correlation Variance: 1.8622383959054213e-05\n",
      "Brier's Score Variance: 9.393358493193886e-07\n",
      "Time Variance: 0.010996093749999996\n"
     ]
    }
   ],
   "source": [
    "negative_precision = [0.92, 0.92, 0.93, 0.92, 0.92]\n",
    "negative_recall = [0.97, 0.97, 0.96, 0.96, 0.96]\n",
    "negative_f1_score = [0.94, 0.94, 0.94, 0.94, 0.94]\n",
    "\n",
    "positive_precision = [0.74, 0.74, 0.73, 0.74, 0.73]\n",
    "positive_recall = [0.56, 0.56, 0.55, 0.55, 0.55]\n",
    "positive_f1_score = [0.64, 0.64, 0.63, 0.63, 0.63]\n",
    "\n",
    "accuracy = [0.90, 0.90, 0.90, 0.90, 0.90]\n",
    "matthews_correlation = [0.5897683347185898, 0.5912042015863317, 0.5893192697464371, 0.5847338869126286, 0.5794291285215211]\n",
    "briers_score = [0.0968011126564673, 0.09638386648122392, 0.09735744089012517, 0.09791376912378304, 0.09916550764951321]\n",
    "time = [6.71875, 6.546875, 6.390625, 6.53125, 6.515625]\n",
    "\n",
    "negative_precision_variance = np.var(negative_precision)\n",
    "negative_recall_variance = np.var(negative_recall)\n",
    "negative_f1_score_variance = np.var(negative_f1_score)\n",
    "\n",
    "positive_precision_variance = np.var(positive_precision)\n",
    "positive_recall_variance = np.var(positive_recall)\n",
    "positive_f1_score_variance = np.var(positive_f1_score)\n",
    "\n",
    "accuracy_variance = np.var(accuracy)\n",
    "matthews_correlation_variance = np.var(matthews_correlation)\n",
    "briers_score_variance = np.var(briers_score)\n",
    "time_variance = np.var(time)\n",
    "\n",
    "# Print the variances\n",
    "print(\"Negative Precision Variance:\", negative_precision_variance)\n",
    "print(\"Negative Recall Variance:\", negative_recall_variance)\n",
    "print(\"Negative F1-score Variance:\", negative_f1_score_variance)\n",
    "\n",
    "print(\"Positive Precision Variance:\", positive_precision_variance)\n",
    "print(\"Positive Recall Variance:\", positive_recall_variance)\n",
    "print(\"Positive F1-score Variance:\", positive_f1_score_variance)\n",
    "\n",
    "print(\"Accuracy Variance:\", accuracy_variance)\n",
    "print(\"Matthew's Correlation Variance:\", matthews_correlation_variance)\n",
    "print(\"Brier's Score Variance:\", briers_score_variance)\n",
    "print(\"Time Variance:\", time_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
