{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4JCoOguwtKhF"
   },
   "outputs": [],
   "source": [
    "#Data processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Model performance metrics\n",
    "from time import process_time\n",
    "from memory_profiler import profile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Feature selection and models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Data scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Function\n",
    "def DTClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  tree_raw_imbalanced = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the Classifier to the data\n",
    "  tree_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = tree_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "def RFClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the Random Forest Classifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the classifier to the data\n",
    "  forest_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = forest_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "def LRClassifier(X_train, y_train, X_test, y_test):\n",
    "  #Initialize the Logistic Regression Classifier\n",
    "  lr_raw_imbalanced = LogisticRegression(max_iter= 100000)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "\n",
    "  #Fit the classifier to the data\n",
    "  lr_raw_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = lr_raw_imbalanced.predict(X_test)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Models to include SMOTE and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Function\n",
    "def DTClassifierMOD(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  tree_raw_imbalanced = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "  \n",
    "  #Data preprocessing\n",
    "  smote = SMOTE()\n",
    "  X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "  # Subset the numeric attributes\n",
    "  X_train_smote_numeric = X_train_smote[numeric_attributes]\n",
    "  X_test_numeric = X_test[numeric_attributes]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X_train_smote_S = scaler.fit_transform(X_train_smote_numeric)\n",
    "  X_test_numeric_S = scaler.transform(X_test_numeric)\n",
    "        \n",
    "  # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "  X_train_combined = np.concatenate((X_train_smote_S, X_train_smote[cat_attributes]), axis=1)\n",
    "  X_test_combined = np.concatenate((X_test_numeric_S, X_test[cat_attributes]), axis=1)\n",
    "\n",
    "  #Fit the Classifier to the data\n",
    "  tree_raw_imbalanced.fit(X_train_combined, y_train_smote)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = tree_raw_imbalanced.predict(X_test_combined)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest function\n",
    "def RFClassifierMOD(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "  \n",
    "  #Data preprocessing\n",
    "  smote = SMOTE()\n",
    "  X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "  # Subset the numeric attributes\n",
    "  X_train_smote_numeric = X_train_smote[numeric_attributes]\n",
    "  X_test_numeric = X_test[numeric_attributes]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X_train_smote_S = scaler.fit_transform(X_train_smote_numeric)\n",
    "  X_test_numeric_S = scaler.transform(X_test_numeric)\n",
    "        \n",
    "  # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "  X_train_combined = np.concatenate((X_train_smote_S, X_train_smote[cat_attributes]), axis=1)\n",
    "  X_test_combined = np.concatenate((X_test_numeric_S, X_test[cat_attributes]), axis=1)\n",
    "\n",
    "  #Fit the Classifier to the data\n",
    "  forest_raw_imbalanced.fit(X_train_combined, y_train_smote)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = forest_raw_imbalanced.predict(X_test_combined)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression function\n",
    "def LRClassifierMOD(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  lr_raw_imbalanced = LogisticRegression(max_iter= 10000)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "  \n",
    "  #Data preprocessing\n",
    "  smote = SMOTE()\n",
    "  X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "  # Subset the numeric attributes\n",
    "  X_train_smote_numeric = X_train_smote[numeric_attributes]\n",
    "  X_test_numeric = X_test[numeric_attributes]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X_train_smote_S = scaler.fit_transform(X_train_smote_numeric)\n",
    "  X_test_numeric_S = scaler.transform(X_test_numeric)\n",
    "        \n",
    "  # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "  X_train_combined = np.concatenate((X_train_smote_S, X_train_smote[cat_attributes]), axis=1)\n",
    "  X_test_combined = np.concatenate((X_test_numeric_S, X_test[cat_attributes]), axis=1)\n",
    "\n",
    "  #Fit the Classifier to the data\n",
    "  lr_raw_imbalanced.fit(X_train_combined, y_train_smote)\n",
    "\n",
    "  #Predict new Data\n",
    "  y_pred = lr_raw_imbalanced.predict(X_test_combined)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  #Results\n",
    "  cr = classification_report(y_test, y_pred)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  time = end_time - start_time\n",
    "  print(cr)\n",
    "  print(cm)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossvalidation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Validation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Function\n",
    "def DTClassifierKFold(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  tree_raw_imbalanced = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  kfold = KFold(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(tree_raw_imbalanced, X_train, y_train, cv = kfold)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "    \n",
    "  for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    tree_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = tree_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Function\n",
    "def RFClassifierKFold(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  kfold = KFold(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(forest_raw_imbalanced, X_train, y_train, cv = kfold)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "    \n",
    "  for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    forest_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = forest_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Function\n",
    "def LRClassifierKFold(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  lr_raw_imbalanced = LogisticRegression(max_iter= 100000)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  kfold = KFold(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(lr_raw_imbalanced, X_train, y_train, cv = kfold)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "    \n",
    "  for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    lr_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = lr_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Function\n",
    "def DTClassifierTS(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  tree_raw_imbalanced = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  knn = KNeighborsClassifier(n_neighbors=1)\n",
    "  tscv = TimeSeriesSplit(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(tree_raw_imbalanced, X_train, y_train, cv = tscv)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "    \n",
    "  for train_index, val_index in tscv.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    tree_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = tree_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Function\n",
    "def RFClassifierTS(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  forest_raw_imbalanced = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  knn = KNeighborsClassifier(n_neighbors=1)\n",
    "  tscv = TimeSeriesSplit(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(forest_raw_imbalanced, X_train, y_train, cv = tscv)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "    \n",
    "  for train_index, val_index in tscv.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    forest_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = forest_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Function\n",
    "def LRClassifierTS(X_train, y_train, X_test, y_test, numeric_attributes, cat_attributes, num_folds):\n",
    "  #Initialize the DecisionTreeClassifier\n",
    "  lr_raw_imbalanced = LogisticRegression(max_iter= 100000)\n",
    "\n",
    "  #Time Measurement\n",
    "  start_time = process_time()\n",
    "    \n",
    "  #Specify number of folds (k) for cross validation\n",
    "  knn = KNeighborsClassifier(n_neighbors=1)\n",
    "  tscv = TimeSeriesSplit(n_splits = num_folds)\n",
    "    \n",
    "  results = cross_val_score(lr_raw_imbalanced, X_train, y_train, cv = tscv)\n",
    "\n",
    "  #Lists for metrics\n",
    "  confusion_matrices = []\n",
    "  classification_reports = []\n",
    "    \n",
    "  all_predictions = []\n",
    "  all_true_labels = []\n",
    "    \n",
    "  for train_index, val_index in tscv.split(X_train):\n",
    "    X_train_fold_values, X_val_fold_values = X_train.values[train_index], X_train.values[val_index]\n",
    "    y_train_fold_values, y_val_fold_values = y_train.values[train_index], y_train.values[val_index]\n",
    "    \n",
    "    X_train_fold = pd.DataFrame(X_train_fold_values, columns=X_train.columns)\n",
    "    X_val_fold = pd.DataFrame(X_val_fold_values, columns=X_train.columns)\n",
    "    y_train_fold = pd.Series(y_train_fold_values, index=X_train_fold.index)\n",
    "    y_val_fold = pd.Series(y_val_fold_values, index=X_val_fold.index)\n",
    "    \n",
    "    X_train_numeric = X_train_fold.loc[:, numeric_attributes]\n",
    "    X_val_numeric = X_val_fold.loc[:, numeric_attributes]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_smote_S = scaler.fit_transform(X_train_numeric)\n",
    "    X_test_numeric_S = scaler.transform(X_val_numeric)\n",
    "    \n",
    "    # Concatenate the standardized numeric attributes with the categorical attributes\n",
    "    X_train_combined = np.concatenate((X_train_smote_S, X_train_fold[cat_attributes]), axis=1)\n",
    "    X_test_combined = np.concatenate((X_test_numeric_S, X_val_fold[cat_attributes]), axis=1)\n",
    "    \n",
    "    #Data preprocessing\n",
    "    smote = SMOTE()\n",
    "    X_train_fold_SMOTE, y_train_fold_SMOTE = smote.fit_resample(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Fit the Classifier to the data\n",
    "    lr_raw_imbalanced.fit(X_train_combined, y_train_fold)\n",
    "\n",
    "    #Predict new Data\n",
    "    y_pred = lr_raw_imbalanced.predict(X_test_combined)\n",
    "    \n",
    "    cr = classification_report(y_val_fold, y_pred)\n",
    "    classification_reports.append(cr)\n",
    "    \n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_val_fold)\n",
    "\n",
    "  #Time Measurement\n",
    "  end_time = process_time()\n",
    "\n",
    "  time = end_time - start_time\n",
    "  summary_report = classification_report(all_true_labels, all_predictions)\n",
    "  \n",
    "  \"\"\"\n",
    "  for fold in range(num_folds):\n",
    "    print(\"Confusion matrix for fold\", fold+1, \":\\n\", confusion_matrices[fold])\n",
    "    print(\"Classification report for fold\", fold+1, \":\\n\", classification_reports[fold])\n",
    "    print()\"\"\"\n",
    "    \n",
    "  print(summary_report)\n",
    "  print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "44OujbUttSSO"
   },
   "outputs": [],
   "source": [
    "#https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KRCsu3r5tZpJ"
   },
   "outputs": [],
   "source": [
    "#Identify categorical attributes\n",
    "categorical_features = [\"Month\", \"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\"]\n",
    "df_cat = df[categorical_features]\n",
    "\n",
    "df_onehot = pd.get_dummies(df, columns = categorical_features, prefix = categorical_features)\n",
    "\n",
    "#Tranform categorical attributes\n",
    "label_encoder = LabelEncoder()\n",
    "df_onehot['Revenue'] = label_encoder.fit_transform(df['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcUOdrF_tlUx"
   },
   "source": [
    "Control SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8rc2Vmy8texw"
   },
   "outputs": [],
   "source": [
    "#Specify independent/ dependent values\n",
    "X = df_onehot.drop(columns = \"Revenue\")\n",
    "y = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpMyEWmOtvjL"
   },
   "source": [
    "# Filtered Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHa8Kv3ptyvM"
   },
   "source": [
    "Pearson Correlation Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HrDrPu0tyFK",
    "outputId": "77ac05e8-4c20-49ec-d89b-e762c8772149"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_9896/4021719917.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pearson['Revenue'] = label_encoder.fit_transform(df_pearson['Revenue'])\n"
     ]
    }
   ],
   "source": [
    "#Correlation of Onehot encoded dataset\n",
    "\n",
    "corr = df_onehot.corr()\n",
    "\n",
    "revenue_correlation = corr[\"Revenue\"]\n",
    "sorted_pearson_correlation = revenue_correlation.abs().sort_values(ascending = False)\n",
    "\n",
    "#Filter out for attributes with correlation > 0.09\n",
    "filtered_correlation = sorted_pearson_correlation[sorted_pearson_correlation > 0.09]\n",
    "filtered_attributes = filtered_correlation.index.tolist()\n",
    "df_pearson = df_onehot[filtered_attributes]\n",
    "\n",
    "#12 attributes (Onehot encoded) are kept\n",
    "\n",
    "#Tranform categorical attributes\n",
    "label_encoder = LabelEncoder()\n",
    "df_pearson['Revenue'] = label_encoder.fit_transform(df_pearson['Revenue'])\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_p = df_pearson.drop(columns = \"Revenue\")\n",
    "y_p = df_pearson[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p, y_p, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_p_train_smote, y_p_train_smote = smote.fit_resample(X_p_train, y_p_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3Mm3aGPuXM0"
   },
   "source": [
    "Random Forest Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEM13opyuB5_",
    "outputId": "739e18dc-171b-43f9-b25a-f990e38acc59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_9896/4019081138.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rf[\"Revenue\"] = df_onehot[\"Revenue\"]\n"
     ]
    }
   ],
   "source": [
    "#Filters of RF Classifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "#Fit random forest classifier\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "rf_df = pd.DataFrame({\"Feature\": X_train_smote.columns, \"Importance\": feature_importances})\n",
    "\n",
    "sorted_features = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "#Sorting features\n",
    "rf_df_sorted = rf_df.sort_values(\"Importance\", ascending = False)\n",
    "rf_df_sorted = rf_df_sorted.reset_index(drop = True)\n",
    "rf_df_sorted\n",
    "\n",
    "#Filter out for attributes with random forest score > 0.009\n",
    "filtered_rf = rf_df_sorted[rf_df_sorted['Importance'] > 0.009]\n",
    "#filtered_attributes_rf = filtered_rf.index.tolist()\n",
    "df_rf = df_onehot[filtered_rf[\"Feature\"]]\n",
    "\n",
    "#24 features are kept after random forest feature selection\n",
    "df_rf[\"Revenue\"] = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_rf = df_rf.drop(columns = \"Revenue\")\n",
    "y_rf = df_rf[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_rf_train_smote, y_rf_train_smote = smote.fit_resample(X_rf_train, y_rf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq5mjUnIwAZm"
   },
   "source": [
    "RFE Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWe3lxDruOBD",
    "outputId": "95f8f52c-61c2-48aa-fe17-2114fd509dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indices: [6, 7, 9, 10, 12, 13, 17, 18, 19, 22, 30, 39, 50, 52, 56, 62, 64, 67, 73, 74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_9896/2182278487.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rfe[\"Revenue\"] = df_onehot[\"Revenue\"]\n"
     ]
    }
   ],
   "source": [
    "#Filter for features with RFE\n",
    "\n",
    "df_X_rfe = df_onehot.drop(columns = \"Revenue\")\n",
    "df_y_rfe = df_onehot[\"Revenue\"]\n",
    "\n",
    "# Instantiate the model and RFE selector\n",
    "model = LogisticRegression(solver = \"liblinear\")\n",
    "rfe_selector = RFE(model, n_features_to_select = 20)\n",
    "\n",
    "# Perform RFE feature selection\n",
    "selected_features = rfe_selector.fit_transform(df_X_rfe, df_y_rfe)\n",
    "\n",
    "# Get the mask of selected features\n",
    "feature_mask = rfe_selector.support_\n",
    "\n",
    "# Get the ranking of features (optional)\n",
    "feature_ranking = rfe_selector.ranking_\n",
    "\n",
    "selected_indices = [i for i, mask in enumerate(feature_mask) if mask]\n",
    "print(\"Selected feature indices:\", selected_indices)\n",
    "\n",
    "df_rfe = df_onehot.iloc[:, selected_indices]\n",
    "\n",
    "#20 features are kept after random forest feature selection\n",
    "df_rfe[\"Revenue\"] = df_onehot[\"Revenue\"]\n",
    "\n",
    "#Specify independent/ dependent values\n",
    "X_rfe = df_rfe.drop(columns = \"Revenue\")\n",
    "y_rfe = df_rfe[\"Revenue\"]\n",
    "\n",
    "#Split the Data\n",
    "X_rfe_train, X_rfe_test, y_rfe_train, y_rfe_test = train_test_split(X_rfe, y_rfe, test_size = 0.3)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_rfe_train_smote, y_rfe_train_smote = smote.fit_resample(X_rfe_train, y_rfe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define columns that need data normalization/ standardization\n",
    "numeric_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "\n",
    "p_numeric_features = ['Administrative', 'Administrative_Duration', 'Informational', \n",
    "       'ProductRelated', 'ProductRelated_Duration','BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "rf_numeric_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "rfe_numeric_features = ['BounceRates', 'ExitRates', 'SpecialDay']\n",
    "\n",
    "cat_features = [col for col in X_train if col not in numeric_features]\n",
    "p_cat_features = [col for col in X_p_train if col not in numeric_features]\n",
    "rf_cat_features = [col for col in X_rf_train if col not in numeric_features]\n",
    "rfe_cat_features = [col for col in X_rfe_train if col not in numeric_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting data to scale numeric features\n",
    "\n",
    "#Control\n",
    "X_train_smote_NUM = X_train_smote[numeric_features]\n",
    "X_test_NUM = X_test[numeric_features]\n",
    "\n",
    "#Pearson correlation features\n",
    "X_p_train_smote_NUM = X_p_train_smote[p_numeric_features]\n",
    "X_p_test_NUM = X_p_test[p_numeric_features]\n",
    "\n",
    "#Random Forest features\n",
    "X_rf_train_smote_NUM = X_rf_train_smote[rf_numeric_features]\n",
    "X_rf_test_NUM = X_rf_test[rf_numeric_features]\n",
    "\n",
    "#Recursive Feature Elimination features\n",
    "X_rfe_train_smote_NUM = X_rfe_train_smote[rfe_numeric_features]\n",
    "X_rfe_test_NUM = X_rfe_test[rfe_numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscaler = StandardScaler()\n",
    "\n",
    "#Scaling control\n",
    "X_train_smote_NUM_S = sscaler.fit_transform(X_train_smote_NUM)\n",
    "X_train_smote_COMBINED_S = np.concatenate((X_train_smote_NUM_S, X_train_smote[cat_features]), axis = 1)\n",
    "                                          \n",
    "X_test_NUM_S = sscaler.transform(X_test_NUM)\n",
    "X_test_COMBINED_S = np.concatenate((X_test_NUM_S, X_test[cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Pearson correlation features\n",
    "X_p_train_smote_NUM_S = sscaler.fit_transform(X_p_train_smote_NUM)\n",
    "X_p_train_smote_COMBINED_S = np.concatenate((X_p_train_smote_NUM_S, X_p_train_smote[p_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_p_test_NUM_S = sscaler.transform(X_p_test_NUM)\n",
    "X_p_test_COMBINED_S = np.concatenate((X_p_test_NUM_S, X_p_test[p_cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Random Forest features\n",
    "X_rf_train_smote_NUM_S = sscaler.fit_transform(X_rf_train_smote_NUM)\n",
    "X_rf_train_smote_COMBINED_S = np.concatenate((X_rf_train_smote_NUM_S, X_rf_train_smote[rf_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_rf_test_NUM_S = sscaler.transform(X_rf_test_NUM)\n",
    "X_rf_test_COMBINED_S = np.concatenate((X_rf_test_NUM_S, X_rf_test[rf_cat_features]), axis = 1)\n",
    "\n",
    "#Scaling Recursive Feature Elimination features\n",
    "X_rfe_train_smote_NUM_S = sscaler.fit_transform(X_rfe_train_smote_NUM)\n",
    "X_rfe_train_smote_COMBINED_S = np.concatenate((X_rfe_train_smote_NUM_S, X_rfe_train_smote[rfe_cat_features]), axis = 1)\n",
    "                                          \n",
    "X_rfe_test_NUM_S = sscaler.transform(X_rfe_test_NUM)\n",
    "X_rfe_test_COMBINED_S = np.concatenate((X_rfe_test_NUM_S, X_rfe_test[rfe_cat_features]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control data - Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      3156\n",
      "           1       0.51      0.57      0.54       543\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.72      0.74      0.73      3699\n",
      "weighted avg       0.86      0.86      0.86      3699\n",
      "\n",
      "[[2861  295]\n",
      " [ 233  310]]\n",
      "0.109375\n",
      "peak memory: 241.14 MiB, increment: 0.92 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_train_smote_COMBINED_S, y_train_smote, X_test_COMBINED_S, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3156\n",
      "           1       0.69      0.61      0.65       543\n",
      "\n",
      "    accuracy                           0.90      3699\n",
      "   macro avg       0.81      0.78      0.80      3699\n",
      "weighted avg       0.90      0.90      0.90      3699\n",
      "\n",
      "[[3009  147]\n",
      " [ 210  333]]\n",
      "1.28125\n",
      "peak memory: 266.11 MiB, increment: 24.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_train_smote_COMBINED_S, y_train_smote, X_test_COMBINED_S, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      3156\n",
      "           1       0.71      0.40      0.51       543\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.81      0.69      0.72      3699\n",
      "weighted avg       0.88      0.89      0.87      3699\n",
      "\n",
      "[[3069   87]\n",
      " [ 326  217]]\n",
      "0.109375\n",
      "peak memory: 249.85 MiB, increment: 9.67 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_train_smote_COMBINED_S, y_train_smote, X_test_COMBINED_S, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      3133\n",
      "           1       0.51      0.64      0.57       566\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.72      0.77      0.74      3699\n",
      "weighted avg       0.87      0.85      0.86      3699\n",
      "\n",
      "[[2788  345]\n",
      " [ 201  365]]\n",
      "0.078125\n",
      "peak memory: 242.38 MiB, increment: 0.85 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_p_train_smote_COMBINED_S, y_p_train_smote, X_p_test_COMBINED_S, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3133\n",
      "           1       0.60      0.76      0.67       566\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.83      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2847  286]\n",
      " [ 137  429]]\n",
      "1.453125\n",
      "peak memory: 260.68 MiB, increment: 18.30 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_p_train_smote_COMBINED_S, y_p_train_smote, X_p_test_COMBINED_S, y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3133\n",
      "           1       0.61      0.70      0.65       566\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.81      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "[[2879  254]\n",
      " [ 171  395]]\n",
      "0.015625\n",
      "peak memory: 243.70 MiB, increment: 1.95 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_p_train_smote_COMBINED_S, y_p_train_smote, X_p_test_COMBINED_S, y_p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest features - standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      3132\n",
      "           1       0.54      0.60      0.57       567\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.75      0.74      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2845  287]\n",
      " [ 226  341]]\n",
      "0.09375\n",
      "peak memory: 242.57 MiB, increment: 0.21 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rf_train_smote_COMBINED_S, y_rf_train_smote, X_rf_test_COMBINED_S, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3132\n",
      "           1       0.65      0.67      0.66       567\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.80      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2924  208]\n",
      " [ 186  381]]\n",
      "1.265625\n",
      "peak memory: 261.07 MiB, increment: 18.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rf_train_smote_COMBINED_S, y_rf_train_smote, X_rf_test_COMBINED_S, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      3132\n",
      "           1       0.58      0.50      0.54       567\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.75      0.72      0.73      3699\n",
      "weighted avg       0.86      0.87      0.86      3699\n",
      "\n",
      "[[2930  202]\n",
      " [ 284  283]]\n",
      "0.03125\n",
      "peak memory: 246.77 MiB, increment: 3.40 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rf_train_smote_COMBINED_S, y_rf_train_smote, X_rf_test_COMBINED_S, y_rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination features - standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80      3127\n",
      "           1       0.23      0.43      0.30       572\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.55      0.58      0.55      3699\n",
      "weighted avg       0.78      0.69      0.72      3699\n",
      "\n",
      "[[2306  821]\n",
      " [ 325  247]]\n",
      "0.046875\n",
      "peak memory: 244.36 MiB, increment: 0.27 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifier(X_rfe_train_smote_COMBINED_S, y_rfe_train_smote, X_rfe_test_COMBINED_S, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      3127\n",
      "           1       0.26      0.38      0.31       572\n",
      "\n",
      "    accuracy                           0.74      3699\n",
      "   macro avg       0.57      0.59      0.58      3699\n",
      "weighted avg       0.78      0.74      0.76      3699\n",
      "\n",
      "[[2515  612]\n",
      " [ 353  219]]\n",
      "1.03125\n",
      "peak memory: 284.61 MiB, increment: 40.24 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifier(X_rfe_train_smote_COMBINED_S, y_rfe_train_smote, X_rfe_test_COMBINED_S, y_rfe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74      3127\n",
      "           1       0.26      0.73      0.38       572\n",
      "\n",
      "    accuracy                           0.63      3699\n",
      "   macro avg       0.59      0.67      0.56      3699\n",
      "weighted avg       0.82      0.63      0.68      3699\n",
      "\n",
      "[[1918 1209]\n",
      " [ 152  420]]\n",
      "0.03125\n",
      "peak memory: 245.09 MiB, increment: 2.71 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifier(X_rfe_train_smote_COMBINED_S, y_rfe_train_smote, X_rfe_test_COMBINED_S, y_rfe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Functions to include oversampling/scaling within the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfiltered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      3156\n",
      "           1       0.49      0.54      0.51       543\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.70      0.72      0.71      3699\n",
      "weighted avg       0.86      0.85      0.85      3699\n",
      "\n",
      "[[2851  305]\n",
      " [ 250  293]]\n",
      "0.953125\n",
      "peak memory: 272.12 MiB, increment: 19.28 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierMOD(X_train, y_train, X_test, y_test, numeric_features, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3156\n",
      "           1       0.69      0.64      0.66       543\n",
      "\n",
      "    accuracy                           0.90      3699\n",
      "   macro avg       0.81      0.80      0.80      3699\n",
      "weighted avg       0.90      0.90      0.90      3699\n",
      "\n",
      "[[2998  158]\n",
      " [ 195  348]]\n",
      "2.15625\n",
      "peak memory: 290.22 MiB, increment: 42.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierMOD(X_train, y_train, X_test, y_test, numeric_features, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      3156\n",
      "           1       0.71      0.40      0.51       543\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.81      0.68      0.72      3699\n",
      "weighted avg       0.88      0.89      0.87      3699\n",
      "\n",
      "[[3069   87]\n",
      " [ 328  215]]\n",
      "0.796875\n",
      "peak memory: 276.15 MiB, increment: 25.96 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierMOD(X_train, y_train, X_test, y_test, numeric_features, cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      3133\n",
      "           1       0.54      0.67      0.60       566\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.74      0.78      0.76      3699\n",
      "weighted avg       0.88      0.86      0.87      3699\n",
      "\n",
      "[[2809  324]\n",
      " [ 189  377]]\n",
      "0.09375\n",
      "peak memory: 255.44 MiB, increment: 7.17 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierMOD(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3133\n",
      "           1       0.61      0.76      0.67       566\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.83      0.80      3699\n",
      "weighted avg       0.90      0.89      0.89      3699\n",
      "\n",
      "[[2854  279]\n",
      " [ 138  428]]\n",
      "1.515625\n",
      "peak memory: 274.02 MiB, increment: 18.59 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierMOD(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3133\n",
      "           1       0.61      0.70      0.65       566\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.81      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "[[2883  250]\n",
      " [ 169  397]]\n",
      "0.03125\n",
      "peak memory: 255.56 MiB, increment: 6.85 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierMOD(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      3132\n",
      "           1       0.53      0.63      0.57       567\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.73      0.76      0.74      3699\n",
      "weighted avg       0.87      0.86      0.86      3699\n",
      "\n",
      "[[2816  316]\n",
      " [ 212  355]]\n",
      "1.03125\n",
      "peak memory: 261.37 MiB, increment: 10.89 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierMOD(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3132\n",
      "           1       0.65      0.67      0.66       567\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.80      0.80      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "[[2927  205]\n",
      " [ 189  378]]\n",
      "2.125\n",
      "peak memory: 277.26 MiB, increment: 21.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierMOD(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      3132\n",
      "           1       0.58      0.50      0.54       567\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.75      0.72      0.73      3699\n",
      "weighted avg       0.86      0.87      0.86      3699\n",
      "\n",
      "[[2930  202]\n",
      " [ 284  283]]\n",
      "0.390625\n",
      "peak memory: 258.92 MiB, increment: 9.64 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierMOD(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80      3127\n",
      "           1       0.22      0.40      0.29       572\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.55      0.57      0.54      3699\n",
      "weighted avg       0.77      0.69      0.72      3699\n",
      "\n",
      "[[2309  818]\n",
      " [ 341  231]]\n",
      "0.625\n",
      "peak memory: 257.93 MiB, increment: 0.07 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierMOD(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      3127\n",
      "           1       0.27      0.39      0.32       572\n",
      "\n",
      "    accuracy                           0.74      3699\n",
      "   macro avg       0.57      0.60      0.58      3699\n",
      "weighted avg       0.78      0.74      0.76      3699\n",
      "\n",
      "[[2513  614]\n",
      " [ 350  222]]\n",
      "1.953125\n",
      "peak memory: 297.46 MiB, increment: 39.48 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierMOD(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74      3127\n",
      "           1       0.26      0.73      0.38       572\n",
      "\n",
      "    accuracy                           0.64      3699\n",
      "   macro avg       0.59      0.68      0.56      3699\n",
      "weighted avg       0.82      0.64      0.69      3699\n",
      "\n",
      "[[1937 1190]\n",
      " [ 152  420]]\n",
      "0.359375\n",
      "peak memory: 259.96 MiB, increment: 7.57 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierMOD(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Crossvalidation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      7266\n",
      "           1       0.57      0.57      0.57      1365\n",
      "\n",
      "    accuracy                           0.86      8631\n",
      "   macro avg       0.74      0.74      0.74      8631\n",
      "weighted avg       0.86      0.86      0.86      8631\n",
      "\n",
      "3.28125\n",
      "peak memory: 278.20 MiB, increment: 23.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierKFold(X_train, y_train, X_test, y_test, numeric_features, cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      7266\n",
      "           1       0.76      0.51      0.61      1365\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.84      0.74      0.78      8631\n",
      "weighted avg       0.89      0.90      0.89      8631\n",
      "\n",
      "9.265625\n",
      "peak memory: 284.53 MiB, increment: 36.75 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierKFold(X_train, y_train, X_test, y_test, numeric_features, cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      7266\n",
      "           1       0.73      0.38      0.50      1365\n",
      "\n",
      "    accuracy                           0.88      8631\n",
      "   macro avg       0.81      0.68      0.71      8631\n",
      "weighted avg       0.87      0.88      0.86      8631\n",
      "\n",
      "4.859375\n",
      "peak memory: 294.61 MiB, increment: 45.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierKFold(X_train, y_train, X_test, y_test, numeric_features, cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      7289\n",
      "           1       0.74      0.56      0.64      1342\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.89      0.90      0.89      8631\n",
      "\n",
      "5.9375\n",
      "peak memory: 262.94 MiB, increment: 13.77 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierKFold(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      7289\n",
      "           1       0.73      0.56      0.63      1342\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.76      0.79      8631\n",
      "weighted avg       0.89      0.90      0.89      8631\n",
      "\n",
      "5.96875\n",
      "peak memory: 262.59 MiB, increment: 10.62 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierKFold(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      7289\n",
      "           1       0.75      0.37      0.50      1342\n",
      "\n",
      "    accuracy                           0.88      8631\n",
      "   macro avg       0.82      0.67      0.72      8631\n",
      "weighted avg       0.87      0.88      0.87      8631\n",
      "\n",
      "0.53125\n",
      "peak memory: 259.11 MiB, increment: 7.21 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierKFold(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7290\n",
      "           1       0.74      0.53      0.62      1341\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.83      0.75      0.78      8631\n",
      "weighted avg       0.89      0.90      0.89      8631\n",
      "\n",
      "9.34375\n",
      "peak memory: 268.55 MiB, increment: 19.80 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierKFold(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      7290\n",
      "           1       0.73      0.53      0.61      1341\n",
      "\n",
      "    accuracy                           0.90      8631\n",
      "   macro avg       0.82      0.74      0.77      8631\n",
      "weighted avg       0.89      0.90      0.89      8631\n",
      "\n",
      "9.28125\n",
      "peak memory: 268.79 MiB, increment: 22.36 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierKFold(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      7290\n",
      "           1       0.73      0.37      0.49      1341\n",
      "\n",
      "    accuracy                           0.88      8631\n",
      "   macro avg       0.81      0.67      0.71      8631\n",
      "weighted avg       0.87      0.88      0.86      8631\n",
      "\n",
      "3.515625\n",
      "peak memory: 269.89 MiB, increment: 23.53 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierKFold(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90      7295\n",
      "           1       0.33      0.17      0.23      1336\n",
      "\n",
      "    accuracy                           0.82      8631\n",
      "   macro avg       0.59      0.55      0.56      8631\n",
      "weighted avg       0.78      0.82      0.79      8631\n",
      "\n",
      "8.109375\n",
      "peak memory: 276.32 MiB, increment: 29.09 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierKFold(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90      7295\n",
      "           1       0.33      0.18      0.23      1336\n",
      "\n",
      "    accuracy                           0.82      8631\n",
      "   macro avg       0.60      0.56      0.56      8631\n",
      "weighted avg       0.78      0.82      0.79      8631\n",
      "\n",
      "8.09375\n",
      "peak memory: 272.44 MiB, increment: 25.52 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierKFold(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      7295\n",
      "           1       0.47      0.01      0.02      1336\n",
      "\n",
      "    accuracy                           0.84      8631\n",
      "   macro avg       0.66      0.50      0.47      8631\n",
      "weighted avg       0.79      0.84      0.78      8631\n",
      "\n",
      "1.6875\n",
      "peak memory: 267.58 MiB, increment: 20.64 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierKFold(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfiltered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      6063\n",
      "           1       0.55      0.54      0.55      1127\n",
      "\n",
      "    accuracy                           0.86      7190\n",
      "   macro avg       0.73      0.73      0.73      7190\n",
      "weighted avg       0.86      0.86      0.86      7190\n",
      "\n",
      "2.125\n",
      "peak memory: 309.43 MiB, increment: 31.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierTS(X_train, y_train, X_test, y_test, numeric_features, cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      6063\n",
      "           1       0.76      0.50      0.60      1127\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.84      0.74      0.77      7190\n",
      "weighted avg       0.89      0.90      0.89      7190\n",
      "\n",
      "6.421875\n",
      "peak memory: 309.37 MiB, increment: 31.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierTS(X_train, y_train, X_test, y_test, numeric_features, cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      6063\n",
      "           1       0.73      0.39      0.51      1127\n",
      "\n",
      "    accuracy                           0.88      7190\n",
      "   macro avg       0.81      0.68      0.72      7190\n",
      "weighted avg       0.87      0.88      0.87      7190\n",
      "\n",
      "4.359375\n",
      "peak memory: 318.91 MiB, increment: 39.76 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierTS(X_train, y_train, X_test, y_test, numeric_features, cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      6041\n",
      "           1       0.58      0.55      0.57      1149\n",
      "\n",
      "    accuracy                           0.87      7190\n",
      "   macro avg       0.75      0.74      0.74      7190\n",
      "weighted avg       0.86      0.87      0.86      7190\n",
      "\n",
      "0.265625\n",
      "peak memory: 290.96 MiB, increment: 11.77 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierTS(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      6041\n",
      "           1       0.77      0.53      0.63      1149\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.84      0.75      0.79      7190\n",
      "weighted avg       0.89      0.90      0.89      7190\n",
      "\n",
      "3.890625\n",
      "peak memory: 290.21 MiB, increment: 13.20 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierTS(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      6041\n",
      "           1       0.75      0.39      0.51      1149\n",
      "\n",
      "    accuracy                           0.88      7190\n",
      "   macro avg       0.82      0.68      0.72      7190\n",
      "weighted avg       0.87      0.88      0.86      7190\n",
      "\n",
      "0.3125\n",
      "peak memory: 286.81 MiB, increment: 4.24 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierTS(X_p_train, y_p_train, X_p_test, y_p_test, p_numeric_features, p_cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      6086\n",
      "           1       0.55      0.57      0.56      1104\n",
      "\n",
      "    accuracy                           0.86      7190\n",
      "   macro avg       0.73      0.74      0.74      7190\n",
      "weighted avg       0.86      0.86      0.86      7190\n",
      "\n",
      "2.40625\n",
      "peak memory: 300.51 MiB, increment: 21.34 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierTS(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      6086\n",
      "           1       0.72      0.52      0.60      1104\n",
      "\n",
      "    accuracy                           0.90      7190\n",
      "   macro avg       0.82      0.74      0.77      7190\n",
      "weighted avg       0.89      0.90      0.89      7190\n",
      "\n",
      "6.0625\n",
      "peak memory: 295.32 MiB, increment: 17.92 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierTS(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      6086\n",
      "           1       0.73      0.39      0.51      1104\n",
      "\n",
      "    accuracy                           0.88      7190\n",
      "   macro avg       0.82      0.68      0.72      7190\n",
      "weighted avg       0.87      0.88      0.87      7190\n",
      "\n",
      "2.859375\n",
      "peak memory: 299.93 MiB, increment: 22.76 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierTS(X_rf_train, y_rf_train, X_rf_test, y_rf_test, rf_numeric_features, rf_cat_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      6074\n",
      "           1       0.24      0.23      0.24      1116\n",
      "\n",
      "    accuracy                           0.76      7190\n",
      "   macro avg       0.55      0.55      0.55      7190\n",
      "weighted avg       0.76      0.76      0.76      7190\n",
      "\n",
      "1.671875\n",
      "peak memory: 290.16 MiB, increment: 11.05 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit DTClassifierTS(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      6074\n",
      "           1       0.33      0.16      0.22      1116\n",
      "\n",
      "    accuracy                           0.82      7190\n",
      "   macro avg       0.59      0.55      0.56      7190\n",
      "weighted avg       0.78      0.82      0.79      7190\n",
      "\n",
      "5.6875\n",
      "peak memory: 303.44 MiB, increment: 25.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit RFClassifierTS(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      6074\n",
      "           1       0.42      0.00      0.01      1116\n",
      "\n",
      "    accuracy                           0.84      7190\n",
      "   macro avg       0.63      0.50      0.46      7190\n",
      "weighted avg       0.78      0.84      0.77      7190\n",
      "\n",
      "1.625\n",
      "peak memory: 294.23 MiB, increment: 15.43 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit LRClassifierTS(X_rfe_train, y_rfe_train, X_rfe_test, y_rfe_test, rfe_numeric_features, rfe_cat_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
